{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3376307f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-17 16:09:20.973449: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-17 16:09:26.469346: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, TrainingArguments, Trainer, AutoModelForSequenceClassification\n",
    "\n",
    "from sklearn.metrics import matthews_corrcoef, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from accelerate import Accelerator\n",
    "import logging\n",
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b077b28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Define the working device\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "947ee686",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmForSequenceClassification were not initialized from the model checkpoint at /hpctmp/e0543831/GPU/InstaDeepAI and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Load the model\n",
    "num_class = 3\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"/hpctmp/e0543831/GPU/InstaDeepAI\", num_labels=num_class)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db379738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Import dataset\n",
    "samples_dataframe_H = pd.read_csv(\"unique_sequences_H.csv\", names=['sequence'])\n",
    "samples_dataframe_M = pd.read_csv(\"unique_sequences_M.csv\", names=['sequence'])\n",
    "samples_dataframe_L = pd.read_csv(\"unique_sequences_L.csv\", names=['sequence'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e1c2a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Data Preprocessing\n",
    "num_random_rows = 1000\n",
    "H_rand = samples_dataframe_H.sample(n=num_random_rows)\n",
    "H_rand = H_rand[~H_rand['sequence'].str.contains('N')]\n",
    "\n",
    "M_rand = samples_dataframe_M.sample(n=num_random_rows)\n",
    "M_rand = M_rand[~M_rand['sequence'].str.contains('N')]\n",
    "\n",
    "L_rand = samples_dataframe_L.sample(n=num_random_rows)\n",
    "L_rand = L_rand[~L_rand['sequence'].str.contains('N')]\n",
    "\n",
    "samples_all = pd.concat([H_rand, M_rand, L_rand])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3efc7a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Creating labels for H, M, L\n",
    "H_perflist_H = [0]*len(H_rand)\n",
    "H_perflist_M = [1]*len(M_rand)\n",
    "H_perflist_L = [2]*len(L_rand)\n",
    "H_perflist = H_perflist_H + H_perflist_M + H_perflist_L\n",
    "\n",
    "H_perflist = np.array(H_perflist)\n",
    "df_temp = pd.DataFrame(H_perflist, columns=['label'], dtype='int32', index=samples_all.index)\n",
    "samples_all = pd.concat([samples_all, df_temp], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02ebfa0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Split the combined dataset into training, validation, and test sets\n",
    "train_ratio = 0.7\n",
    "val_ratio = 0.1\n",
    "test_ratio = 0.2\n",
    "\n",
    "train_data, val_test_data = train_test_split(samples_all, test_size=val_ratio + test_ratio, random_state=42)\n",
    "val_data, test_data = train_test_split(val_test_data, test_size=test_ratio / (val_ratio + test_ratio), random_state=42)\n",
    "\n",
    "train_sequences = train_data['sequence'].tolist()\n",
    "train_labels = train_data['label'].tolist()\n",
    "\n",
    "val_sequences = val_data['sequence'].tolist()\n",
    "val_labels = val_data['label'].tolist()\n",
    "\n",
    "test_sequences = test_data['sequence'].tolist()\n",
    "test_labels = test_data['label'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea038a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [[3, 436, 2032, 1933], [3, 2891, 4104, 4104, 4104, 4104, 4100, 4101, 4102], [3, 4100, 4101, 4102, 4103]], 'attention_mask': [[1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1]]}\n"
     ]
    }
   ],
   "source": [
    "# In [8]:\n",
    "### TOKENINIZING THE DATASET ###\n",
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/hpctmp/e0543831/GPU/InstaDeepAI\")\n",
    "sequences = [\"ATCGAATGGCGATGCACT\", \"CGTATGNNNNATC\", \"ATCG\"]\n",
    "batch_tokens_ids = tokenizer(sequences)\n",
    "print(batch_tokens_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a6725fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In [9]:\n",
    "# Convert the split dataframes to Hugging Face Datasets\n",
    "train_dataset = Dataset.from_dict({\"data\": train_sequences, 'labels': train_labels})\n",
    "val_dataset = Dataset.from_dict({\"data\": val_sequences, 'labels': val_labels})\n",
    "test_dataset = Dataset.from_dict({\"data\": test_sequences, 'labels': test_labels})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a75a7bcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a3f17685b0e4ee3af602f3879ae7f61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/208541 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61911bb418764bc7ae4b2385c767f0fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/29791 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05ee203c9a814e6d8fcb88a2f6afc915",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/59584 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# In [10]:\n",
    "def tokenize_function(examples):\n",
    "    outputs = tokenizer(examples[\"data\"])\n",
    "    return outputs\n",
    "\n",
    "# Tokenize the datasets\n",
    "tokenized_train_dataset = train_dataset.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    remove_columns=[\"data\"],\n",
    ")\n",
    "\n",
    "tokenized_val_dataset = val_dataset.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    remove_columns=[\"data\"],\n",
    ")\n",
    "\n",
    "tokenized_test_dataset = test_dataset.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    remove_columns=[\"data\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35f06578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In [11]:\n",
    "batch_size = 64\n",
    "model_name = 'NLP_New_Varying_dataset_64batchsize_3000steps_Data_MCC'\n",
    "args = TrainingArguments(\n",
    "    f\"{model_name}-finetuned-NucleotideTransformer\",\n",
    "    remove_unused_columns=False,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    learning_rate=1e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    gradient_accumulation_steps=1,\n",
    "    per_device_eval_batch_size=64,\n",
    "    num_train_epochs=30,\n",
    "    logging_steps=1000,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"mcc_score\",\n",
    "    label_names=[\"labels\"],\n",
    "    dataloader_drop_last=True,\n",
    "    max_steps=3000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5be717ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In [12]:\n",
    "\"\"\"Next, we define the metric we will use to evaluate our models and write a `compute_metrics` function. We can load this from the `scikit-learn` library.\"\"\"\n",
    "def compute_metrics_mcc(eval_pred):\n",
    "    predictions = np.argmax(eval_pred.predictions, axis=-1)\n",
    "    references = eval_pred.label_ids\n",
    "    r = {'mcc_score': matthews_corrcoef(references, predictions)}\n",
    "    return r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "941f4516",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "2024-04-05 16:38:35.227989: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-05 16:38:37.599559: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# In [13]:\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics_mcc,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59db2c3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2501' max='3000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2501/3000 2:32:35 < 30:28, 0.27 it/s, Epoch 0.77/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Mcc Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.106000</td>\n",
       "      <td>1.094487</td>\n",
       "      <td>0.084472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.075200</td>\n",
       "      <td>1.046371</td>\n",
       "      <td>0.176522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.048300</td>\n",
       "      <td>1.036089</td>\n",
       "      <td>0.192384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.023200</td>\n",
       "      <td>0.971641</td>\n",
       "      <td>0.298321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.982700</td>\n",
       "      <td>0.918440</td>\n",
       "      <td>0.350893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.918700</td>\n",
       "      <td>1.067807</td>\n",
       "      <td>0.320830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.899400</td>\n",
       "      <td>0.850642</td>\n",
       "      <td>0.435815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.816300</td>\n",
       "      <td>0.789669</td>\n",
       "      <td>0.483083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.794500</td>\n",
       "      <td>0.786543</td>\n",
       "      <td>0.475785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.771600</td>\n",
       "      <td>0.754754</td>\n",
       "      <td>0.512856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.761900</td>\n",
       "      <td>0.719438</td>\n",
       "      <td>0.539891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.727300</td>\n",
       "      <td>0.712178</td>\n",
       "      <td>0.544949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.719200</td>\n",
       "      <td>0.711246</td>\n",
       "      <td>0.550832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.683300</td>\n",
       "      <td>0.684347</td>\n",
       "      <td>0.565708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.699200</td>\n",
       "      <td>0.692879</td>\n",
       "      <td>0.562759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.671300</td>\n",
       "      <td>0.652309</td>\n",
       "      <td>0.587228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.647800</td>\n",
       "      <td>0.650933</td>\n",
       "      <td>0.589557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.645400</td>\n",
       "      <td>0.641911</td>\n",
       "      <td>0.593977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.651000</td>\n",
       "      <td>0.632735</td>\n",
       "      <td>0.601195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.641500</td>\n",
       "      <td>0.636329</td>\n",
       "      <td>0.600659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.610200</td>\n",
       "      <td>0.633113</td>\n",
       "      <td>0.606130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.652200</td>\n",
       "      <td>0.619377</td>\n",
       "      <td>0.614539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.626000</td>\n",
       "      <td>0.623116</td>\n",
       "      <td>0.611377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.625600</td>\n",
       "      <td>0.613836</td>\n",
       "      <td>0.614094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='188' max='465' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [188/465 01:27 < 02:10, 2.13 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# In [14]:\n",
    "\"\"\"We can now finetune our model by just calling the `train` method:\"\"\"\n",
    "train_results = trainer.train()\n",
    "\n",
    "print(train_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948d912a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In [15]:\n",
    "\"\"\"As with the first task, the time can be greatly reduced by increasing the batch size.\n",
    "\n",
    "#### **Validation MCC score**\n",
    "\"\"\"\n",
    "\n",
    "curve_evaluation_mcc_score = [[a['step'], a['eval_mcc_score']] for a in trainer.state.log_history if 'eval_mcc_score' in a.keys()]\n",
    "eval_mcc_score = [c[1] for c in curve_evaluation_mcc_score]\n",
    "steps = [c[0] for c in curve_evaluation_mcc_score]\n",
    "\n",
    "plt.plot(steps, eval_mcc_score, 'b', label='Validation MCC score')\n",
    "plt.title('Validation MCC score for enhancer prediction')\n",
    "plt.xlabel('Number of training steps performed')\n",
    "plt.ylabel('Validation MCC score')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0302f021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In [16]:\n",
    "# \"\"\"#### **MCC on the test dataset**\"\"\"\n",
    "\n",
    "# # Compute the MCC score on the test dataset :\n",
    "print(f\"MCC score on the test dataset: {trainer.predict(tokenized_test_dataset).metrics['test_mcc_score']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdebcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In [17]:\n",
    "#### **Validation F1 score**\n",
    "#curve_evaluation_f1_score =[[a['step'],a['eval_f1_score']] for a in trainer.state.log_history if 'eval_f1_score' in a.keys()]\n",
    "#eval_f1_score = [c[1] for c in curve_evaluation_f1_score]\n",
    "#steps = [c[0] for c in curve_evaluation_f1_score]\n",
    "\n",
    "#plt.plot(steps, eval_f1_score, 'b', label='Validation F1 score')\n",
    "#plt.title('Validation F1 score for promoter prediction')\n",
    "#plt.xlabel('Number of training steps performed')\n",
    "#plt.ylabel('Validation F1 score')\n",
    "#plt.legend()\n",
    "#plt.show()\n",
    "# Compute the F1 score on the test dataset :\n",
    "#print(f\"F1 score on the test dataset: {trainer.predict(tokenized_test_dataset).metrics['test_f1_score']}\")\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5ec091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory paths to save the model and tokenizer\n",
    "output_dir = 'trained_model_GPU_' + model_name\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "model.save_pretrained(output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06cc1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(output_dir)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508fc6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data, either FNS from Jingyun or Generated from Sangeetha\n",
    "\n",
    "FNS_dataframe = pd.read_csv('FNS Sequences for ML model validation.csv')\n",
    "# FNS_dataframe = pd.read_csv('Sangeetha_Seq_for_verification.csv')\n",
    "\n",
    "# Data preprocessing: Extracting the DNA samples\n",
    "FNS_dataframe = FNS_dataframe.dropna()\n",
    "FNS_samples = FNS_dataframe['Sample']\n",
    "FNS_samples.reset_index(drop=True, inplace=True)\n",
    "FNS_sequence = FNS_dataframe['DNA Sequence']\n",
    "FNS_sequence.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Extract sequences from the DataFrame\n",
    "new_sequences = FNS_sequence.tolist()\n",
    "\n",
    "# Tokenize the new sequences\n",
    "tokenized_sequences = tokenizer(new_sequences, return_tensors=\"pt\", padding=True, truncation=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b49f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform inference\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(**tokenized_sequences)\n",
    "\n",
    "# Get the predicted labels\n",
    "predicted_labels = torch.argmax(outputs.logits, dim=1).tolist()\n",
    "class_mapping = {0: 'High', 1: 'Medium, 2: 'Low'}\n",
    "predicted_labels = [class_mapping[idx] for idx in predicted_labels]\n",
    "# Add the predicted labels to the DataFrame\n",
    "FNS_dataframe['Predicted_Labels'] = predicted_labels\n",
    "\n",
    "# Save the DataFrame with predicted labels\n",
    "FNS_dataframe.to_csv(output_dir + '_FNS_Predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7869186d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d007dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.read_csv('JY_Exp_Results.csv')\n",
    "Count_Correct = 0\n",
    "for i in range(len(x)):\n",
    "    if x['Exp Classification'][i] == predicted_labels[i]:\n",
    "        Count_Correct +=1 \n",
    "\n",
    "Correct_Percentage = Count_Correct/len(x) * 100\n",
    "print(\"Percentage of correct predictions using Jing Yun's Data: \" + str(Correct_Percentage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0e2bad",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "predict = trainer.predict(tokenized_test_dataset)\n",
    "prediction = []\n",
    "for i in predict[0]:\n",
    "    prediction.append(np.array(i).argmax())\n",
    "\n",
    "prediction = [int(i) for i in prediction]\n",
    "class_mapping = {0: 'High', 1: 'Medium, 2: 'Low'}\n",
    "predicted_labels = [class_mapping[idx] for idx in prediction]\n",
    "predicted_labels_series = pd.Series(predicted_labels, name='Predicted_Labels')\n",
    "\n",
    "\n",
    "new_data_with_predictions = pd.concat([FNS_samples, predicted_labels_series], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf153e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_test2 = [int(i) for i in tokenized_test_dataset['labels']]\n",
    "# Dictionary to store counts of integers\n",
    "count_dict = {}\n",
    "count_dict[0] = 0\n",
    "count_dict[1] = 0\n",
    "count_dict[2] = 0\n",
    "\n",
    "# Count occurrences of integers in the list\n",
    "for i in y_test2:\n",
    "    if i==0:\n",
    "        count_dict[0] += 1\n",
    "    elif i==1:\n",
    "        count_dict[1] += 1\n",
    "    elif i==2:\n",
    "        count_dict[2] += 1\n",
    "\n",
    "# Print the counts of integers\n",
    "for num, count in count_dict.items():\n",
    "    print(f\"The integer {num} appears {count} time(s) in the list.\")\n",
    "    \n",
    "n_High,n_Medium,n_Low = count_dict.values()\n",
    "count_High,count_Medium,count_Low = 0,0,0\n",
    "\n",
    "#n_High,n_Low = count_dict.values()\n",
    "#count_High,count_Low = 0,0\n",
    "\n",
    "for i in range(len(prediction)):\n",
    "    if prediction[i] == y_test2[i] and prediction[i] == 0:\n",
    "        count_High += 1\n",
    "    elif prediction[i] == y_test2[i] and prediction[i] == 1:\n",
    "        count_Medium += 1\n",
    "    elif prediction[i] == y_test2[i] and prediction[i] == 2:\n",
    "        count_Low += 1\n",
    "\n",
    "Correct_High = count_High/n_High * 100\n",
    "Correct_Medium = count_Medium/n_Medium * 100\n",
    "Correct_Low = count_Low/n_Low * 100\n",
    "\n",
    "results_RF2 = {'Correctly Predicted-High': Correct_High,\n",
    "           'Correctly Predicted-Medium': Correct_Medium, \\\n",
    "           'Correctly Predicted-Low':Correct_Low}\n",
    "print(results_RF2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0539b2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(output_dir + '_accuracy', 'w') as f:\n",
    "    for key, value in results_RF2.items(): \n",
    "        f.write('%s:%s\\n' % (key, value))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0966014",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
